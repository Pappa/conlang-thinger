{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2949, 8, 42)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_phonemes = np.load(\"./data/language_phonemes.npy\", allow_pickle=True)\n",
    "language_names = np.load(\"./data/language_names.npy\", allow_pickle=True)[:, 0]\n",
    "\n",
    "assert language_phonemes.shape[0] == language_names.shape[0]\n",
    "language_phonemes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Iron Ossetic', 10), ('Dutch', 9), ('Basque', 6), ('Laz', 6), ('Northeastern Thai', 5)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((342,), (342, 8, 42), (8, 42), 2740)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_names, unique_names_count = np.unique(language_names, return_counts=True)\n",
    "multiple_samples = unique_names[unique_names_count > 1]\n",
    "\n",
    "count_sort_idx_desc = np.argsort(-unique_names_count)\n",
    "\n",
    "most_common_languages = list(\n",
    "    zip(unique_names[count_sort_idx_desc], unique_names_count[count_sort_idx_desc])\n",
    ")\n",
    "\n",
    "print(most_common_languages[0:5])\n",
    "\n",
    "X = language_phonemes[np.in1d(language_names, multiple_samples)]\n",
    "y = language_names[np.in1d(language_names, multiple_samples)]\n",
    "\n",
    "sample_shape = X[0].shape\n",
    "num_classes = len(unique_names)\n",
    "\n",
    "y.shape, X.shape, sample_shape, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((208, 2740), (134, 2740))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.39, random_state=33)\n",
    "\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAACKCAYAAAD2fAPCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAPa0lEQVR4nO3dfUyV9f/H8dcB5KjJjYZyE0rgDc4baGIwVloL5s1aM23OzD/InE7DTTNb2pY3/YPTzZnOZVvr6z9NjBa52mopCq1CU5SplUwYJU6QdBMQBR18fn80Tj9E0QOfcy7O8fnYrg2uc3mu9/t6y3jt4jrX5TLGGAEAAFgQ4nQBAAAgeBAsAACANQQLAABgDcECAABYQ7AAAADWECwAAIA1BAsAAGANwQIAAFgT5s+ddXZ26sqVK4qIiJDL5fLnrgEAQB8ZY9TS0qKEhASFhPR+TsKvweLKlSsaPXq0P3cJAAAsqaurU2JiYq/b9ClY7N27Vzt27FBDQ4PS09O1Z88eZWZmPvTfRURESJI++eQTDRkypC+7fqj58+f75H39obi42GfvHcjHxdd8edwljr1TvJ2rr+c00OrxpaioKK+2b2pq8lEl6I23c5L++z3eG6+DxcGDB7Vu3Trt27dPWVlZ2rVrl2bPnq2qqiqNGjWq13/b9eePIUOGaOjQod7u+pFERkb65H39wVfHRArs4+JrvjzuEsfeKd7O1ddzGmj1DCSPU6+B7lEuY/D64s2dO3dq+fLlWrp0qSZNmqR9+/Zp6NCh+vzzz/tUJAAACB5eBYs7d+6ooqJCubm5/71BSIhyc3NVXl5uvTgAABBYvPpTyLVr19TR0aHY2Nhu62NjY3XhwoUe27e3t6u9vd3zfXNzcx/LBAAAgcCn97EoKChQVFSUZ+ETIQAABDevgkVMTIxCQ0N19erVbuuvXr2quLi4Httv3LhRTU1NnqWurq5/1QIAgAHNq2ARHh6ujIwMlZSUeNZ1dnaqpKRE2dnZPbZ3u92KjIzstgAAgODl9cdN161bp7y8PE2fPl2ZmZnatWuXWltbtXTpUl/UBwAAAojXwWLRokX6559/tGnTJjU0NOiZZ57RDz/80OOCTgAA8PhxGWOMv3bW3NysqKgoNTU1PfKfRbx9pogf23FcUVHRI2+7cOFCH1byePHmuEscewCBz5vf3zzdFAAAWEOwAAAA1hAsAACANQQLAABgDcECAABYQ7AAAADWECwAAIA1BAsAAGANwQIAAFhDsAAAANYQLAAAgDUD/lkhANDF2+e0eINnugAPxrNCAACAIwgWAADAGoIFAACwhmABAACsIVgAAABrCBYAAMAaggUAALCGYAEAAKwhWAAAAGsIFgAAwBqCBQAAsCbM6QLQd948N4HnICAY8P84MLhcLq+29+Mjq/D/eDunR8UZCwAAYA3BAgAAWEOwAAAA1hAsAACANQQLAABgDcECAABYQ7AAAADWECwAAIA1BAsAAGANwQIAAFjDLb0HEG9u0T2Q3lsK7Fste3tsArlXXwvkY8nPiD3cojsweDOn5uZmRUVFPdK2nLEAAADWECwAAIA1BAsAAGANwQIAAFhDsAAAANYQLAAAgDUECwAAYA3BAgAAWEOwAAAA1hAsAACANQQLAABgjcv48abuXfcab2pqUmRkpL92CwAA+sGb39+csQAAANZ4FSy2bNkil8vVbZk4caKvagMAAAHG68emT548WUeOHPnvDcJ48joAAPiX16kgLCxMcXFxvqgFAAAEOK+vsbh48aISEhKUkpKiJUuW6NKlS76oCwAABCCvzlhkZWVp//79Sk1NVX19vbZu3aoZM2bo/PnzioiI6LF9e3u72tvbPd83Nzf3v2IAADBg9evjpjdu3FBSUpJ27typZcuW9Xh9y5Yt2rp1a4/1fNwUAIDA4bePm0ZHR2vChAmqrq6+7+sbN25UU1OTZ6mrq+vP7gAAwADXr2Bx8+ZN1dTUKD4+/r6vu91uRUZGdlsAAEDw8ipYrF+/XmVlZfrrr7/066+/av78+QoNDdXixYt9VR8AAAggXl28efnyZS1evFjXr1/XyJEj9fzzz+v48eMaOXKkr+oDAAABxKtgUVhY6Ks6AGuKioq82n7hwoU+qgR4PLlcLq+29+Mjq+AHPCsEAABYQ7AAAADWECwAAIA1BAsAAGANwQIAAFhDsAAAANYQLAAAgDUECwAAYA3BAgAAWEOwAAAA1hAsAACANV49KwQIBDz7A3AWz/54vHHGAgAAWEOwAAAA1hAsAACANQQLAABgDcECAABYQ7AAAADWECwAAIA1BAsAAGANwQIAAFhDsAAAANb49ZbeXbd5bW5u9uduAQBAP3T93n6U27X7NVi0tLRIkkaPHu3P3QIAAAtaWloUFRXV6zYu48enxXR2durKlSuKiIiQy+XyrG9ubtbo0aNVV1enyMhIf5XjCHoNXo9Tv/QanOg1ONno1RijlpYWJSQkKCSk96so/HrGIiQkRImJiQ98PTIyMugH3IVeg9fj1C+9Bid6DU797fVhZyq6cPEmAACwhmABAACsGRDBwu12a/PmzXK73U6X4nP0Grwep37pNTjRa3Dyd69+vXgTAAAEtwFxxgIAAAQHggUAALCGYAEAAKwhWAAAAGsGRLDYu3evnn76aQ0ePFhZWVn67bffnC7Jui1btsjlcnVbJk6c6HRZVvz000965ZVXlJCQIJfLpW+++abb68YYbdq0SfHx8RoyZIhyc3N18eJFZ4rtp4f1+uabb/aY85w5c5wptp8KCgr07LPPKiIiQqNGjdKrr76qqqqqbtu0tbUpPz9fTz75pIYNG6bXXntNV69edajivnuUXl988cUes125cqVDFffdJ598orS0NM/NkrKzs/X99997Xg+WmUoP7zVYZno/27Ztk8vl0tq1az3r/DVbx4PFwYMHtW7dOm3evFmnT59Wenq6Zs+ercbGRqdLs27y5Mmqr6/3LD///LPTJVnR2tqq9PR07d27976vb9++Xbt379a+fft04sQJPfHEE5o9e7ba2tr8XGn/PaxXSZozZ063OR84cMCPFdpTVlam/Px8HT9+XIcPH9bdu3c1a9Ystba2erZ555139O2336qoqEhlZWW6cuWKFixY4GDVffMovUrS8uXLu812+/btDlXcd4mJidq2bZsqKip06tQpvfTSS5o3b55+//13ScEzU+nhvUrBMdN7nTx5Up9++qnS0tK6rffbbI3DMjMzTX5+vuf7jo4Ok5CQYAoKChysyr7Nmzeb9PR0p8vwOUmmuLjY831nZ6eJi4szO3bs8Ky7ceOGcbvd5sCBAw5UaM+9vRpjTF5enpk3b54j9fhaY2OjkWTKysqMMf/OcdCgQaaoqMizzZ9//mkkmfLycqfKtOLeXo0x5oUXXjBr1qxxrigfGj58uPnss8+CeqZduno1Jjhn2tLSYsaPH28OHz7crT9/ztbRMxZ37txRRUWFcnNzPetCQkKUm5ur8vJyByvzjYsXLyohIUEpKSlasmSJLl265HRJPldbW6uGhoZuM46KilJWVlZQzliSSktLNWrUKKWmpmrVqlW6fv260yVZ0dTUJEkaMWKEJKmiokJ3797tNtuJEydqzJgxAT/be3vt8sUXXygmJkZTpkzRxo0bdevWLSfKs6ajo0OFhYVqbW1VdnZ2UM/03l67BNtM8/Pz9fLLL3eboeTfn1e/PoTsXteuXVNHR4diY2O7rY+NjdWFCxccqso3srKytH//fqWmpqq+vl5bt27VjBkzdP78eUVERDhdns80NDRI0n1n3PVaMJkzZ44WLFig5ORk1dTU6IMPPtDcuXNVXl6u0NBQp8vrs87OTq1du1bPPfecpkyZIunf2YaHhys6OrrbtoE+2/v1KklvvPGGkpKSlJCQoLNnz+r9999XVVWVvv76awer7Ztz584pOztbbW1tGjZsmIqLizVp0iRVVlYG3Uwf1KsUXDOVpMLCQp0+fVonT57s8Zo/f14dDRaPk7lz53q+TktLU1ZWlpKSkvTll19q2bJlDlYGm15//XXP11OnTlVaWprGjh2r0tJS5eTkOFhZ/+Tn5+v8+fNBc11Qbx7U64oVKzxfT506VfHx8crJyVFNTY3Gjh3r7zL7JTU1VZWVlWpqatJXX32lvLw8lZWVOV2WTzyo10mTJgXVTOvq6rRmzRodPnxYgwcPdrQWR/8UEhMTo9DQ0B5XpV69elVxcXEOVeUf0dHRmjBhgqqrq50uxae65vg4zliSUlJSFBMTE9BzXr16tb777jsdO3ZMiYmJnvVxcXG6c+eObty40W37QJ7tg3q9n6ysLEkKyNmGh4dr3LhxysjIUEFBgdLT0/Xxxx8H5Uwf1Ov9BPJMKyoq1NjYqGnTpiksLExhYWEqKyvT7t27FRYWptjYWL/N1tFgER4eroyMDJWUlHjWdXZ2qqSkpNvfwILRzZs3VVNTo/j4eKdL8ank5GTFxcV1m3Fzc7NOnDgR9DOWpMuXL+v69esBOWdjjFavXq3i4mIdPXpUycnJ3V7PyMjQoEGDus22qqpKly5dCrjZPqzX+6msrJSkgJztvTo7O9Xe3h5UM32Qrl7vJ5BnmpOTo3PnzqmystKzTJ8+XUuWLPF87bfZWr0UtA8KCwuN2+02+/fvN3/88YdZsWKFiY6ONg0NDU6XZtW7775rSktLTW1trfnll19Mbm6uiYmJMY2NjU6X1m8tLS3mzJkz5syZM0aS2blzpzlz5oz5+++/jTHGbNu2zURHR5tDhw6Zs2fPmnnz5pnk5GRz+/Zthyv3Xm+9trS0mPXr15vy8nJTW1trjhw5YqZNm2bGjx9v2tranC7da6tWrTJRUVGmtLTU1NfXe5Zbt255tlm5cqUZM2aMOXr0qDl16pTJzs422dnZDlbdNw/rtbq62nz00Ufm1KlTpra21hw6dMikpKSYmTNnOly59zZs2GDKyspMbW2tOXv2rNmwYYNxuVzmxx9/NMYEz0yN6b3XYJrpg9z7qRd/zdbxYGGMMXv27DFjxowx4eHhJjMz0xw/ftzpkqxbtGiRiY+PN+Hh4eapp54yixYtMtXV1U6XZcWxY8eMpB5LXl6eMebfj5x++OGHJjY21rjdbpOTk2OqqqqcLbqPeuv11q1bZtasWWbkyJFm0KBBJikpySxfvjxgQ/L9+pRk/ve//3m2uX37tnn77bfN8OHDzdChQ838+fNNfX29c0X30cN6vXTpkpk5c6YZMWKEcbvdZty4cea9994zTU1NzhbeB2+99ZZJSkoy4eHhZuTIkSYnJ8cTKowJnpka03uvwTTTB7k3WPhrtjw2HQAAWOP4nTcBAEDwIFgAAABrCBYAAMAaggUAALCGYAEAAKwhWAAAAGsIFgAAwBqCBQAAsIZgAQAArCFYAAAAawgWAADAGoIFAACw5v8AcazcO5xR63oAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X[0], cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape=(8, 42)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"language_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"language_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">336</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">43,136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2740</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">353,460</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_8 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m336\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m43,136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2740\u001b[0m)           │       \u001b[38;5;34m353,460\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">396,596</span> (1.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m396,596\u001b[0m (1.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">396,596</span> (1.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m396,596\u001b[0m (1.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create network architecture\n",
    "\n",
    "input_shape = X[0].shape\n",
    "\n",
    "print(f\"shape={input_shape}\")\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(128, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ],\n",
    "    name=\"language_model\"\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilation\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 8, 42)\n",
      "(208, 2740)\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 7.9047\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0150 - loss: 7.7949    \n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0059 - loss: 7.6457    \n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0470 - loss: 7.4009\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0244 - loss: 7.1368    \n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0371 - loss: 6.7517\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0658 - loss: 6.2473 \n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0458 - loss: 5.6790\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0587 - loss: 5.2256\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0564 - loss: 4.9159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x13fe79610>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0459 - loss: 5.4225  \n",
      "Classes: 2740\n",
      "Samples per language: 13.17\n",
      "Random guess probability: 0.00036\n",
      "Most common language probability: 0.00365\n",
      "5 most common language probability: 0.01314\n",
      "Model accuracy: 0.03731\n"
     ]
    }
   ],
   "source": [
    "# accuracy doesn't look great, but it's not bad considering there\n",
    "# is only one training sample of many of the languages and the\n",
    "# number of classes is in the thousands\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Classes: {num_classes}\")\n",
    "print(f\"Samples per language: {num_classes / len(y_train):.2f}\")\n",
    "print(f\"Random guess probability: {1 / num_classes:.5f}\")\n",
    "print(\n",
    "    f\"Most common language probability: {most_common_languages[0][1] / num_classes:.5f}\"\n",
    ")\n",
    "print(\n",
    "    f\"5 most common language probability: {np.sum([y for _, y in most_common_languages[0:5]]) / num_classes:.5f}\"\n",
    ")\n",
    "print(f\"Model accuracy: {test_acc:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 30 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x14113c5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "Correct preditions: 6.0%\n",
      "Predicted form top 5: 82.0%\n"
     ]
    }
   ],
   "source": [
    "# The predictions are heavily skewed towards languages that appear multiple\n",
    "# times in the dataset (to be expected really). So, to genrate synthetic examples\n",
    "# that don't just copy the most common languages, it'll probably be necessary to \n",
    "# limit the trainling data for synthetic data genertion to 1 example or a small \n",
    "# number of examples per language.\n",
    "\n",
    "num_samples = 50\n",
    "top_n_languages = set([name for name, _ in most_common_languages[0:5]])\n",
    "\n",
    "predictions = label_encoder.inverse_transform(\n",
    "    model.predict(X_test[0:num_samples]).argmax(axis=-1)\n",
    ")\n",
    "actual = label_encoder.inverse_transform(y_test[0:num_samples].argmax(axis=-1))\n",
    "\n",
    "correct_predictions = sum([1 if p == a else 0 for p, a in zip(predictions, actual)])\n",
    "\n",
    "predicted_from_common = sum([1 if p in top_n_languages else 0 for p in predictions])\n",
    "\n",
    "print(f\"Correct preditions: {correct_predictions / len(predictions) * 100}%\")\n",
    "print(f\"Predicted from top 5: {predicted_from_common / len(predictions) * 100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
