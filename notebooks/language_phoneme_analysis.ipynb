{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2949,), (2949, 8, 42))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_phonemes = np.load(\"./data/language_phonemes.npy\", allow_pickle=True).astype(int)\n",
    "language_names = np.load(\"./data/language_names.npy\", allow_pickle=True)[:, 0]\n",
    "\n",
    "assert language_phonemes.shape[0] == language_names.shape[0]\n",
    "language_names.shape, language_phonemes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For languages that have multiple samples in the Phoible dataset, we need to select a way of choosing one sample or combine multiple samples into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_names, unique_names_count = np.unique(language_names, return_counts=True)\n",
    "multiple_samples = unique_names[unique_names_count > 1]\n",
    "single_sample = unique_names[unique_names_count == 1]\n",
    "\n",
    "language_data = {\n",
    "    name: {\"data\": language_phonemes[language_names == name]} for name in unique_names\n",
    "}\n",
    "\n",
    "# sense check\n",
    "for name in unique_names:\n",
    "    assert (\n",
    "        language_phonemes[language_names == name].shape\n",
    "        == language_data[name][\"data\"].shape\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_values = np.sort(np.unique(language_phonemes))\n",
    "# all_values = all_values[all_values > 0]\n",
    "\n",
    "for name, v in language_data.items():\n",
    "    if name in multiple_samples:\n",
    "        v[\"min\"] = np.min(v[\"data\"], axis=0)\n",
    "        v[\"max\"] = np.max(v[\"data\"], axis=0)\n",
    "        v[\"mean\"] = np.rint(np.mean(v[\"data\"], axis=0))\n",
    "        v[\"diff\"] = v[\"max\"] - v[\"min\"]\n",
    "    else:\n",
    "        v[\"min\"] = v[\"data\"][0]\n",
    "        v[\"max\"] = v[\"data\"][0]\n",
    "        v[\"mean\"] = v[\"data\"][0]\n",
    "        v[\"diff\"] = np.zeros(v[\"data\"][0].shape)\n",
    "\n",
    "    min, min_counts = np.unique(v[\"min\"], return_counts=True)\n",
    "    max, max_counts = np.unique(v[\"max\"], return_counts=True)\n",
    "\n",
    "    counts = [\n",
    "        *[0 if n not in min else min_counts[np.where(min == n)][0] for n in all_values],\n",
    "        *[0 if n not in max else max_counts[np.where(max == n)][0] for n in all_values],\n",
    "    ]\n",
    "    v[\"counts\"] = np.array(counts)\n",
    "\n",
    "# sense check\n",
    "assert all(\n",
    "    [\n",
    "        metric.shape == language_phonemes.shape[1:]\n",
    "        for k, v in language_data.items()\n",
    "        for n, metric in v.items()\n",
    "        if n != \"data\" and n != \"counts\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Remo</th>\n",
       "      <td>9</td>\n",
       "      <td>97</td>\n",
       "      <td>56.0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iron Ossetic</th>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>18.0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Laz</th>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>21.0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lithuanian</th>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>34.0</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spanish</th>\n",
       "      <td>3</td>\n",
       "      <td>84</td>\n",
       "      <td>23.0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             min max  mean diff\n",
       "Remo           9  97  56.0   88\n",
       "Iron Ossetic   0  88  18.0   88\n",
       "Laz            3  90  21.0   87\n",
       "Lithuanian     4  87  34.0   83\n",
       "Spanish        3  84  23.0   81"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_stats = np.array(\n",
    "    [\n",
    "        [name, v[\"min\"].sum(), v[\"max\"].sum(), v[\"mean\"].sum(), v[\"diff\"].sum()]\n",
    "        for name, v in language_data.items()\n",
    "        if name in multiple_samples\n",
    "    ]\n",
    ")\n",
    "\n",
    "lang_stats_df = pd.DataFrame(\n",
    "    lang_stats[:, 1:], index=lang_stats[:, 0], columns=[\"min\", \"max\", \"mean\", \"diff\"]\n",
    ").sort_values(\"diff\", ascending=False)\n",
    "lang_stats_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above shows a huge difference between max/min values in each sample.\n",
    "\n",
    "The values shown are sums of all the values in the language_phoneme matrix for each language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_min</th>\n",
       "      <th>1_min</th>\n",
       "      <th>2_min</th>\n",
       "      <th>3_min</th>\n",
       "      <th>0_max</th>\n",
       "      <th>1_max</th>\n",
       "      <th>2_max</th>\n",
       "      <th>3_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Shan</th>\n",
       "      <td>331</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>291</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Remo</th>\n",
       "      <td>327</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>295</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mingrelian</th>\n",
       "      <td>327</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>283</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lithuanian</th>\n",
       "      <td>332</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>295</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English (British)</th>\n",
       "      <td>321</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>305</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kabardian</th>\n",
       "      <td>331</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>293</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greek</th>\n",
       "      <td>321</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Western Balochi</th>\n",
       "      <td>329</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>296</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Friulian</th>\n",
       "      <td>330</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spanish</th>\n",
       "      <td>333</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>282</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0_min  1_min  2_min  3_min  0_max  1_max  2_max  3_max\n",
       "Shan                 331      5      0      0    291     11      1     33\n",
       "Remo                 327      9      0      0    295     13      0     28\n",
       "Mingrelian           327      9      0      0    283     24      2     27\n",
       "Lithuanian           332      4      0      0    295     18      0     23\n",
       "English (British)    321     15      0      0    305      7      1     23\n",
       "Kabardian            331      5      0      0    293     22      0     21\n",
       "Greek                321     15      0      0    292     24      1     19\n",
       "Western Balochi      329      7      0      0    296     22      0     18\n",
       "Friulian             330      6      0      0    307     11      0     18\n",
       "Spanish              333      3      0      0    282     38      2     14"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phoneme_type_counts = np.array(\n",
    "    [v[\"counts\"] for name, v in language_data.items() if name in multiple_samples]\n",
    ")\n",
    "\n",
    "phoneme_type_counts_df = pd.DataFrame(\n",
    "    phoneme_type_counts,\n",
    "    index=lang_stats[:, 0],\n",
    "    columns=[f\"{v}_min\" for v in all_values] + [f\"{v}_max\" for v in all_values],\n",
    ").sort_values(\"3_max\", ascending=False)\n",
    "phoneme_type_counts_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems most of the difference can be explained by some datasets including information on phoneme length. In the language_phoneme matrix, a bitmaks-like encoding was used. \n",
    "\n",
    "- 0 = phoneme not present\n",
    "- 1 = phoneme present (regular length)\n",
    "- 2 = phoneme present (long length)\n",
    "- 3 = phoneme present (regular & long length)\n",
    "\n",
    "Based on that knowledge, it probably makes sense to use the `max` sample for each language. It probably contains the most phonemes for the language and also encodes more information about each phoneme than samples lacking any data on phoneme length."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
